{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27eb2819-930d-4c73-9db6-d8999f2a6ebf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os, sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Subset\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from dataset import MaskBaseDataset, MaskSplitByProfileDataset, TestDataset, CustomAugmentation\n",
    "import model \n",
    "from loss import FocalLoss\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "SEED = 123\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "800d98ba-a4fc-400c-bd1e-16bf84a7d495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성된 모델을 저장할 폴더 (mask, gender, age)\n",
    "# for 문에서 사용할 변수들\n",
    "RESULT_PATH = ['k-fold-mask-b4', 'k-fold-gender-b4', 'k-fold-age-b4']\n",
    "TARGET = ['mask','gender', 'age']\n",
    "CLASS = [3, 2, 3]\n",
    "# if not os.path.exists(RESULT_PATH):\n",
    "#     os.mkdir(RESULT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3483fa7-7d1e-45b6-be93-85b2a0f04a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "num_workers = 4\n",
    "learning_rate = 1e-4\n",
    "lr_decay_step = 5\n",
    "classes_num = 18\n",
    "criterion_name = 'focal'\n",
    "\n",
    "train_log_interval = 20\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f441a2-2e44-4768-8623-6efdcc5758d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DataLoader 생성 함수 (baseline과 동일)\n",
    "def get_dataloader(dataset, train_idx, valid_idx, batch_size, num_workers):\n",
    "    train_set = torch.utils.data.Subset(dataset, indices=train_idx)\n",
    "    val_set = torch.utils.data.Subset(dataset, indices=valid_idx)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last = True,\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        val_set,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    return train_loader, val_loader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aae385fd-67c4-406c-9db1-82b5915dcc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 로드 클래스 (baseline에서 class_by 부분 추가=> __init__, __getitem__)\n",
    "dataset = MaskSplitByProfileDataset(data_dir = '../../input/data/train/images', class_by='mask')\n",
    "transform = CustomAugmentation(resize=(256, 256), mean=dataset.mean, std=dataset.std)\n",
    "dataset.set_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e75b5e8b-eaf0-450b-9942-302047dcad6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6634"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.__len__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "690cdead-9401-44b3-bb7c-bac6d9c967eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficientnetb4(classes):\n",
    "    model = EfficientNet.from_pretrained('efficientnet-b4', num_classes=classes)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b452c4a4-422b-4866-97fc-13e1fa4feba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def undersampling(k, inputs, labels):\n",
    "    if k == 0:\n",
    "        if labels == 0:\n",
    "            return np.random.randint(3)\n",
    "        else:\n",
    "            return 0\n",
    "    elif k == 1:\n",
    "        return 0\n",
    "    else:\n",
    "        if labels != 2:\n",
    "            return np.random.randint(3)\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98e8b376-4a78-47a1-ae03-54170be3561f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.4045 || train accuracy 59.69% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.1677 || train accuracy 91.56% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.05813 || train accuracy 95.55% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.02906 || train accuracy 97.27% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 94.35%, loss: 0.02 || best acc: 94.35%, best loss:0.02\n",
      "Epoch[1/10] (20/82) || training loss 0.0209 || train accuracy 98.83% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.0139 || train accuracy 98.67% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.0113 || train accuracy 99.06% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.01239 || train accuracy 99.30% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.16%, loss: 0.0043 || best acc: 96.16%, best loss:0.0043\n",
      "Epoch[2/10] (20/82) || training loss 0.003481 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.004322 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.006139 || train accuracy 99.53% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.003425 || train accuracy 99.84% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.16%, loss: 0.0048 || best acc: 96.16%, best loss:0.0043\n",
      "Epoch[3/10] (20/82) || training loss 0.002475 || train accuracy 100.00% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.002837 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.001838 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.002815 || train accuracy 99.77% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.01%, loss: 0.0077 || best acc: 96.16%, best loss:0.0043\n",
      "Epoch[4/10] (20/82) || training loss 0.001285 || train accuracy 99.92% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.003497 || train accuracy 99.61% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.001438 || train accuracy 99.92% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.001159 || train accuracy 99.92% || lr [0.0001]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 96.08%, loss: 0.0064 || best acc: 96.16%, best loss:0.0043\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.3567 || train accuracy 69.84% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.1327 || train accuracy 93.20% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.0535 || train accuracy 95.70% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.02192 || train accuracy 98.36% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.03%, loss: 0.019 || best acc: 95.03%, best loss:0.019\n",
      "Epoch[1/10] (20/82) || training loss 0.01212 || train accuracy 98.91% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.007153 || train accuracy 99.38% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.008137 || train accuracy 99.45% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.007141 || train accuracy 99.69% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.16%, loss: 0.0041 || best acc: 96.16%, best loss:0.0041\n",
      "Epoch[2/10] (20/82) || training loss 0.006853 || train accuracy 99.45% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.003407 || train accuracy 99.92% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.003469 || train accuracy 99.69% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.003712 || train accuracy 99.77% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.01%, loss: 0.0032 || best acc: 96.16%, best loss:0.0032\n",
      "Epoch[3/10] (20/82) || training loss 0.002379 || train accuracy 99.92% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.001738 || train accuracy 99.92% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.002451 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.001905 || train accuracy 99.77% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.16%, loss: 0.0022 || best acc: 96.16%, best loss:0.0022\n",
      "Epoch[4/10] (20/82) || training loss 0.002048 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.001143 || train accuracy 99.92% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.0007577 || train accuracy 100.00% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.002191 || train accuracy 99.69% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.23%, loss: 0.0014 || best acc: 96.23%, best loss:0.0014\n",
      "Epoch[5/10] (20/82) || training loss 0.001348 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[5/10] (40/82) || training loss 0.0008277 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[5/10] (60/82) || training loss 0.00124 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[5/10] (80/82) || training loss 0.001692 || train accuracy 99.84% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.23%, loss: 0.0023 || best acc: 96.23%, best loss:0.0014\n",
      "Epoch[6/10] (20/82) || training loss 0.0004905 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[6/10] (40/82) || training loss 0.0005644 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[6/10] (60/82) || training loss 0.001515 || train accuracy 99.77% || lr [5e-05]\n",
      "Epoch[6/10] (80/82) || training loss 0.0008358 || train accuracy 99.92% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.31%, loss: 0.0025 || best acc: 96.31%, best loss:0.0014\n",
      "Epoch[7/10] (20/82) || training loss 0.0005168 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[7/10] (40/82) || training loss 0.0005915 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[7/10] (60/82) || training loss 0.0006667 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[7/10] (80/82) || training loss 0.000714 || train accuracy 99.92% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.31%, loss: 0.0028 || best acc: 96.31%, best loss:0.0014\n",
      "Epoch[8/10] (20/82) || training loss 0.0009722 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[8/10] (40/82) || training loss 0.00141 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[8/10] (60/82) || training loss 0.0004192 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[8/10] (80/82) || training loss 0.0008352 || train accuracy 99.84% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.23%, loss: 0.0039 || best acc: 96.31%, best loss:0.0014\n",
      "Epoch[9/10] (20/82) || training loss 0.000433 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[9/10] (40/82) || training loss 0.000823 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[9/10] (60/82) || training loss 0.0003784 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[9/10] (80/82) || training loss 0.0004545 || train accuracy 100.00% || lr [5e-05]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 96.16%, loss: 0.0031 || best acc: 96.31%, best loss:0.0014\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.3611 || train accuracy 67.97% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.1267 || train accuracy 94.38% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.05214 || train accuracy 96.48% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.02699 || train accuracy 98.36% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.33%, loss: 0.023 || best acc: 95.33%, best loss:0.023\n",
      "Epoch[1/10] (20/82) || training loss 0.01448 || train accuracy 98.83% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.009221 || train accuracy 99.22% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.005293 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.003143 || train accuracy 99.92% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.63%, loss: 0.017 || best acc: 95.63%, best loss:0.017\n",
      "Epoch[2/10] (20/82) || training loss 0.003262 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.003256 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.003323 || train accuracy 99.69% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.004292 || train accuracy 99.69% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.86%, loss: 0.015 || best acc: 95.86%, best loss:0.015\n",
      "Epoch[3/10] (20/82) || training loss 0.003418 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.00321 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.003457 || train accuracy 99.61% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.00127 || train accuracy 100.00% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.78%, loss: 0.017 || best acc: 95.86%, best loss:0.015\n",
      "Epoch[4/10] (20/82) || training loss 0.001453 || train accuracy 99.92% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.001765 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.001576 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.0007627 || train accuracy 100.00% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.86%, loss: 0.015 || best acc: 95.86%, best loss:0.015\n",
      "Epoch[5/10] (20/82) || training loss 0.0007391 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[5/10] (40/82) || training loss 0.0007475 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[5/10] (60/82) || training loss 0.001366 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[5/10] (80/82) || training loss 0.0005663 || train accuracy 100.00% || lr [5e-05]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 95.86%, loss: 0.016 || best acc: 95.86%, best loss:0.015\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.3732 || train accuracy 66.88% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.1367 || train accuracy 93.52% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.04837 || train accuracy 95.78% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.03197 || train accuracy 97.19% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.03%, loss: 0.019 || best acc: 95.03%, best loss:0.019\n",
      "Epoch[1/10] (20/82) || training loss 0.01509 || train accuracy 98.83% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.005907 || train accuracy 99.69% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.01373 || train accuracy 99.06% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.009598 || train accuracy 99.30% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.86%, loss: 0.0066 || best acc: 95.86%, best loss:0.0066\n",
      "Epoch[2/10] (20/82) || training loss 0.007329 || train accuracy 99.38% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.004745 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.006626 || train accuracy 99.45% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.002255 || train accuracy 99.92% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.16%, loss: 0.0035 || best acc: 96.16%, best loss:0.0035\n",
      "Epoch[3/10] (20/82) || training loss 0.004484 || train accuracy 99.53% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.002537 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.001121 || train accuracy 100.00% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.002243 || train accuracy 99.77% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.16%, loss: 0.0027 || best acc: 96.16%, best loss:0.0027\n",
      "Epoch[4/10] (20/82) || training loss 0.002439 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.00262 || train accuracy 99.69% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.0007393 || train accuracy 99.92% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.001537 || train accuracy 99.84% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.31%, loss: 0.0019 || best acc: 96.31%, best loss:0.0019\n",
      "Epoch[5/10] (20/82) || training loss 0.001918 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[5/10] (40/82) || training loss 0.00117 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[5/10] (60/82) || training loss 0.001386 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[5/10] (80/82) || training loss 0.002507 || train accuracy 99.77% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.38%, loss: 0.0015 || best acc: 96.38%, best loss:0.0015\n",
      "Epoch[6/10] (20/82) || training loss 0.0008513 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[6/10] (40/82) || training loss 0.001272 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[6/10] (60/82) || training loss 0.001176 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[6/10] (80/82) || training loss 0.000945 || train accuracy 99.92% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.38%, loss: 0.0024 || best acc: 96.38%, best loss:0.0015\n",
      "Epoch[7/10] (20/82) || training loss 0.0006596 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[7/10] (40/82) || training loss 0.0006854 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[7/10] (60/82) || training loss 0.0008655 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[7/10] (80/82) || training loss 0.0003125 || train accuracy 100.00% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.38%, loss: 0.0011 || best acc: 96.38%, best loss:0.0011\n",
      "Epoch[8/10] (20/82) || training loss 0.001617 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[8/10] (40/82) || training loss 0.0006312 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[8/10] (60/82) || training loss 0.000486 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[8/10] (80/82) || training loss 0.0008404 || train accuracy 99.92% || lr [5e-05]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 96.31%, loss: 0.0014 || best acc: 96.38%, best loss:0.0011\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.3795 || train accuracy 64.45% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.1384 || train accuracy 93.28% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.05009 || train accuracy 96.56% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.03757 || train accuracy 96.80% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 94.87%, loss: 0.018 || best acc: 94.87%, best loss:0.018\n",
      "Epoch[1/10] (20/82) || training loss 0.01519 || train accuracy 98.67% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.009416 || train accuracy 99.38% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.01359 || train accuracy 99.38% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.005265 || train accuracy 99.45% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.15%, loss: 0.0049 || best acc: 96.15%, best loss:0.0049\n",
      "Epoch[2/10] (20/82) || training loss 0.003993 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.005754 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.004156 || train accuracy 99.53% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.005101 || train accuracy 99.53% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.15%, loss: 0.004 || best acc: 96.15%, best loss:0.004\n",
      "Epoch[3/10] (20/82) || training loss 0.00239 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.003071 || train accuracy 99.92% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.001736 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.005087 || train accuracy 99.61% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.00%, loss: 0.0064 || best acc: 96.15%, best loss:0.004\n",
      "Epoch[4/10] (20/82) || training loss 0.001762 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.002263 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.002755 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.00112 || train accuracy 100.00% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.38%, loss: 0.0044 || best acc: 96.38%, best loss:0.004\n",
      "Epoch[5/10] (20/82) || training loss 0.0008171 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[5/10] (40/82) || training loss 0.001488 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[5/10] (60/82) || training loss 0.001967 || train accuracy 99.77% || lr [5e-05]\n",
      "Epoch[5/10] (80/82) || training loss 0.0006923 || train accuracy 100.00% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.38%, loss: 0.0051 || best acc: 96.38%, best loss:0.004\n",
      "Epoch[6/10] (20/82) || training loss 0.0006447 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[6/10] (40/82) || training loss 0.002107 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[6/10] (60/82) || training loss 0.0006083 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[6/10] (80/82) || training loss 0.001172 || train accuracy 99.92% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.38%, loss: 0.0052 || best acc: 96.38%, best loss:0.004\n",
      "Epoch[7/10] (20/82) || training loss 0.001396 || train accuracy 99.77% || lr [5e-05]\n",
      "Epoch[7/10] (40/82) || training loss 0.001036 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[7/10] (60/82) || training loss 0.0004024 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[7/10] (80/82) || training loss 0.001121 || train accuracy 99.92% || lr [5e-05]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 96.30%, loss: 0.0042 || best acc: 96.38%, best loss:0.004\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.1355 || train accuracy 73.12% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.07181 || train accuracy 91.09% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.04199 || train accuracy 94.06% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.03922 || train accuracy 94.92% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 92.54%, loss: 0.044 || best acc: 92.54%, best loss:0.044\n",
      "Epoch[1/10] (20/82) || training loss 0.01681 || train accuracy 98.05% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.01737 || train accuracy 97.81% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.01633 || train accuracy 98.28% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.01469 || train accuracy 97.81% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.13%, loss: 0.025 || best acc: 95.13%, best loss:0.025\n",
      "Epoch[2/10] (20/82) || training loss 0.007142 || train accuracy 99.45% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.007655 || train accuracy 99.30% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.004562 || train accuracy 99.53% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.005828 || train accuracy 99.22% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.89%, loss: 0.027 || best acc: 95.89%, best loss:0.025\n",
      "Epoch[3/10] (20/82) || training loss 0.003969 || train accuracy 99.61% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.003963 || train accuracy 99.53% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.004678 || train accuracy 99.69% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.002403 || train accuracy 99.77% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.81%, loss: 0.03 || best acc: 95.89%, best loss:0.025\n",
      "Epoch[4/10] (20/82) || training loss 0.00298 || train accuracy 99.69% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.002218 || train accuracy 99.69% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.002199 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.001915 || train accuracy 99.84% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.28%, loss: 0.036 || best acc: 95.89%, best loss:0.025\n",
      "Epoch[5/10] (20/82) || training loss 0.001082 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[5/10] (40/82) || training loss 0.001468 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[5/10] (60/82) || training loss 0.001217 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[5/10] (80/82) || training loss 0.003375 || train accuracy 99.53% || lr [5e-05]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 95.43%, loss: 0.034 || best acc: 95.89%, best loss:0.025\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.1463 || train accuracy 70.23% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.0746 || train accuracy 91.48% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.04399 || train accuracy 94.22% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.02711 || train accuracy 96.48% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 92.38%, loss: 0.039 || best acc: 92.38%, best loss:0.039\n",
      "Epoch[1/10] (20/82) || training loss 0.01732 || train accuracy 97.81% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.0178 || train accuracy 97.73% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.01318 || train accuracy 97.89% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.01282 || train accuracy 98.83% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 94.28%, loss: 0.026 || best acc: 94.28%, best loss:0.026\n",
      "Epoch[2/10] (20/82) || training loss 0.006337 || train accuracy 99.38% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.006713 || train accuracy 99.06% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.008199 || train accuracy 99.06% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.004697 || train accuracy 99.53% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 94.97%, loss: 0.024 || best acc: 94.97%, best loss:0.024\n",
      "Epoch[3/10] (20/82) || training loss 0.003533 || train accuracy 99.61% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.005174 || train accuracy 99.61% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.004455 || train accuracy 99.61% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.003594 || train accuracy 99.53% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 94.89%, loss: 0.026 || best acc: 94.97%, best loss:0.024\n",
      "Epoch[4/10] (20/82) || training loss 0.003698 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.00287 || train accuracy 99.92% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.002182 || train accuracy 99.92% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.00226 || train accuracy 99.69% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 94.74%, loss: 0.032 || best acc: 94.97%, best loss:0.024\n",
      "Epoch[5/10] (20/82) || training loss 0.001436 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[5/10] (40/82) || training loss 0.001383 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[5/10] (60/82) || training loss 0.002444 || train accuracy 99.69% || lr [5e-05]\n",
      "Epoch[5/10] (80/82) || training loss 0.003329 || train accuracy 99.77% || lr [5e-05]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 94.89%, loss: 0.029 || best acc: 94.97%, best loss:0.024\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.1388 || train accuracy 72.89% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.07209 || train accuracy 89.61% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.0474 || train accuracy 92.97% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.03134 || train accuracy 96.02% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 93.29%, loss: 0.034 || best acc: 93.29%, best loss:0.034\n",
      "Epoch[1/10] (20/82) || training loss 0.01774 || train accuracy 97.97% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.01916 || train accuracy 97.89% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.01813 || train accuracy 98.28% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.01327 || train accuracy 98.59% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.58%, loss: 0.016 || best acc: 95.58%, best loss:0.016\n",
      "Epoch[2/10] (20/82) || training loss 0.005825 || train accuracy 99.69% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.007743 || train accuracy 99.06% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.006296 || train accuracy 99.30% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.01174 || train accuracy 98.67% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.19%, loss: 0.013 || best acc: 96.19%, best loss:0.013\n",
      "Epoch[3/10] (20/82) || training loss 0.005472 || train accuracy 99.38% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.004213 || train accuracy 99.69% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.003549 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.003501 || train accuracy 99.77% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.88%, loss: 0.012 || best acc: 96.19%, best loss:0.012\n",
      "Epoch[4/10] (20/82) || training loss 0.002133 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.004041 || train accuracy 99.53% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.001639 || train accuracy 99.77% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.001846 || train accuracy 99.77% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.04%, loss: 0.015 || best acc: 96.19%, best loss:0.012\n",
      "Epoch[5/10] (20/82) || training loss 0.001428 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[5/10] (40/82) || training loss 0.002248 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[5/10] (60/82) || training loss 0.001727 || train accuracy 99.77% || lr [5e-05]\n",
      "Epoch[5/10] (80/82) || training loss 0.002247 || train accuracy 99.69% || lr [5e-05]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 96.11%, loss: 0.011 || best acc: 96.19%, best loss:0.011\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.1394 || train accuracy 72.50% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.07477 || train accuracy 90.70% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.0489 || train accuracy 93.52% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.02906 || train accuracy 96.48% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 94.66%, loss: 0.031 || best acc: 94.66%, best loss:0.031\n",
      "Epoch[1/10] (20/82) || training loss 0.02017 || train accuracy 97.66% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.01891 || train accuracy 97.89% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.0129 || train accuracy 98.67% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.01236 || train accuracy 98.59% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 94.74%, loss: 0.029 || best acc: 94.74%, best loss:0.029\n",
      "Epoch[2/10] (20/82) || training loss 0.008751 || train accuracy 99.38% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.006799 || train accuracy 99.22% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.006047 || train accuracy 99.30% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.005615 || train accuracy 99.45% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.04%, loss: 0.026 || best acc: 96.04%, best loss:0.026\n",
      "Epoch[3/10] (20/82) || training loss 0.00456 || train accuracy 99.61% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.003134 || train accuracy 99.69% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.002165 || train accuracy 100.00% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.004784 || train accuracy 99.38% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.27%, loss: 0.025 || best acc: 96.27%, best loss:0.025\n",
      "Epoch[4/10] (20/82) || training loss 0.002968 || train accuracy 99.45% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.00167 || train accuracy 99.92% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.001842 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.001854 || train accuracy 99.84% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.27%, loss: 0.025 || best acc: 96.27%, best loss:0.025\n",
      "Epoch[5/10] (20/82) || training loss 0.001653 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[5/10] (40/82) || training loss 0.001443 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[5/10] (60/82) || training loss 0.001119 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[5/10] (80/82) || training loss 0.001077 || train accuracy 99.84% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.34%, loss: 0.028 || best acc: 96.34%, best loss:0.025\n",
      "Epoch[6/10] (20/82) || training loss 0.001171 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[6/10] (40/82) || training loss 0.001441 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[6/10] (60/82) || training loss 0.0007712 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[6/10] (80/82) || training loss 0.001743 || train accuracy 99.84% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.57%, loss: 0.026 || best acc: 96.57%, best loss:0.025\n",
      "Epoch[7/10] (20/82) || training loss 0.000996 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[7/10] (40/82) || training loss 0.001577 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[7/10] (60/82) || training loss 0.001351 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[7/10] (80/82) || training loss 0.0008048 || train accuracy 100.00% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.27%, loss: 0.027 || best acc: 96.57%, best loss:0.025\n",
      "Epoch[8/10] (20/82) || training loss 0.0008724 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[8/10] (40/82) || training loss 0.001247 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[8/10] (60/82) || training loss 0.001946 || train accuracy 99.61% || lr [5e-05]\n",
      "Epoch[8/10] (80/82) || training loss 0.0009219 || train accuracy 100.00% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 96.42%, loss: 0.026 || best acc: 96.57%, best loss:0.025\n",
      "Epoch[9/10] (20/82) || training loss 0.001101 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[9/10] (40/82) || training loss 0.0009541 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[9/10] (60/82) || training loss 0.001039 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[9/10] (80/82) || training loss 0.0009583 || train accuracy 99.92% || lr [5e-05]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 96.57%, loss: 0.026 || best acc: 96.57%, best loss:0.025\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.1323 || train accuracy 74.06% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.06551 || train accuracy 91.80% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.04476 || train accuracy 94.06% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.02912 || train accuracy 96.33% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 91.08%, loss: 0.046 || best acc: 91.08%, best loss:0.046\n",
      "Epoch[1/10] (20/82) || training loss 0.0169 || train accuracy 97.97% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.01899 || train accuracy 98.36% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.01267 || train accuracy 98.91% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.01078 || train accuracy 98.59% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 93.90%, loss: 0.033 || best acc: 93.90%, best loss:0.033\n",
      "Epoch[2/10] (20/82) || training loss 0.006052 || train accuracy 99.45% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.007252 || train accuracy 99.22% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.006837 || train accuracy 99.14% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.005497 || train accuracy 99.38% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 94.21%, loss: 0.033 || best acc: 94.21%, best loss:0.033\n",
      "Epoch[3/10] (20/82) || training loss 0.005952 || train accuracy 99.14% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.003739 || train accuracy 99.69% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.00365 || train accuracy 99.61% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.002975 || train accuracy 99.61% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 94.36%, loss: 0.033 || best acc: 94.36%, best loss:0.033\n",
      "Epoch[4/10] (20/82) || training loss 0.002931 || train accuracy 99.53% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.002093 || train accuracy 99.84% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.004707 || train accuracy 99.53% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.003143 || train accuracy 99.61% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 94.21%, loss: 0.041 || best acc: 94.36%, best loss:0.033\n",
      "Epoch[5/10] (20/82) || training loss 0.001407 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[5/10] (40/82) || training loss 0.001776 || train accuracy 99.77% || lr [5e-05]\n",
      "Epoch[5/10] (60/82) || training loss 0.002635 || train accuracy 99.77% || lr [5e-05]\n",
      "Epoch[5/10] (80/82) || training loss 0.002948 || train accuracy 99.69% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 94.51%, loss: 0.038 || best acc: 94.51%, best loss:0.033\n",
      "Epoch[6/10] (20/82) || training loss 0.0006931 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[6/10] (40/82) || training loss 0.002543 || train accuracy 99.61% || lr [5e-05]\n",
      "Epoch[6/10] (60/82) || training loss 0.002102 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[6/10] (80/82) || training loss 0.001296 || train accuracy 99.84% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 95.27%, loss: 0.029 || best acc: 95.27%, best loss:0.029\n",
      "Epoch[7/10] (20/82) || training loss 0.0007844 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[7/10] (40/82) || training loss 0.001628 || train accuracy 99.77% || lr [5e-05]\n",
      "Epoch[7/10] (60/82) || training loss 0.001212 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[7/10] (80/82) || training loss 0.001593 || train accuracy 99.92% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 94.66%, loss: 0.038 || best acc: 95.27%, best loss:0.029\n",
      "Epoch[8/10] (20/82) || training loss 0.0006379 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[8/10] (40/82) || training loss 0.0008698 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[8/10] (60/82) || training loss 0.0006394 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[8/10] (80/82) || training loss 0.001036 || train accuracy 100.00% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 94.28%, loss: 0.039 || best acc: 95.27%, best loss:0.029\n",
      "Epoch[9/10] (20/82) || training loss 0.0007478 || train accuracy 99.92% || lr [5e-05]\n",
      "Epoch[9/10] (40/82) || training loss 0.0003923 || train accuracy 100.00% || lr [5e-05]\n",
      "Epoch[9/10] (60/82) || training loss 0.001591 || train accuracy 99.84% || lr [5e-05]\n",
      "Epoch[9/10] (80/82) || training loss 0.0005072 || train accuracy 100.00% || lr [5e-05]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 94.74%, loss: 0.038 || best acc: 95.27%, best loss:0.029\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.4225 || train accuracy 53.91% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.2793 || train accuracy 77.42% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.1808 || train accuracy 83.75% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.1369 || train accuracy 83.98% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 73.78%, loss: 0.22 || best acc: 73.78%, best loss:0.22\n",
      "Epoch[1/10] (20/82) || training loss 0.1044 || train accuracy 86.95% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.08655 || train accuracy 89.84% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.07901 || train accuracy 91.56% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.07156 || train accuracy 90.62% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 80.72%, loss: 0.16 || best acc: 80.72%, best loss:0.16\n",
      "Epoch[2/10] (20/82) || training loss 0.04963 || train accuracy 94.61% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.04387 || train accuracy 94.69% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.03867 || train accuracy 95.39% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.04832 || train accuracy 94.06% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 83.31%, loss: 0.14 || best acc: 83.31%, best loss:0.14\n",
      "Epoch[3/10] (20/82) || training loss 0.03045 || train accuracy 96.72% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.0271 || train accuracy 97.03% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.02132 || train accuracy 97.11% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.01792 || train accuracy 98.44% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 84.53%, loss: 0.16 || best acc: 84.53%, best loss:0.14\n",
      "Epoch[4/10] (20/82) || training loss 0.01422 || train accuracy 98.67% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.01497 || train accuracy 98.83% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.0122 || train accuracy 98.67% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.01365 || train accuracy 98.75% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 82.93%, loss: 0.19 || best acc: 84.53%, best loss:0.14\n",
      "Epoch[5/10] (20/82) || training loss 0.009153 || train accuracy 98.91% || lr [5e-05]\n",
      "Epoch[5/10] (40/82) || training loss 0.009335 || train accuracy 98.83% || lr [5e-05]\n",
      "Epoch[5/10] (60/82) || training loss 0.00865 || train accuracy 99.22% || lr [5e-05]\n",
      "Epoch[5/10] (80/82) || training loss 0.008393 || train accuracy 99.14% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 83.84%, loss: 0.19 || best acc: 84.53%, best loss:0.14\n",
      "Epoch[6/10] (20/82) || training loss 0.009127 || train accuracy 99.30% || lr [5e-05]\n",
      "Epoch[6/10] (40/82) || training loss 0.005252 || train accuracy 99.61% || lr [5e-05]\n",
      "Epoch[6/10] (60/82) || training loss 0.0079 || train accuracy 99.22% || lr [5e-05]\n",
      "Epoch[6/10] (80/82) || training loss 0.006177 || train accuracy 99.38% || lr [5e-05]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 83.54%, loss:  0.2 || best acc: 84.53%, best loss:0.14\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.4278 || train accuracy 53.52% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.2744 || train accuracy 76.41% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.1933 || train accuracy 81.33% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.147 || train accuracy 83.20% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 78.12%, loss: 0.17 || best acc: 78.12%, best loss:0.17\n",
      "Epoch[1/10] (20/82) || training loss 0.1034 || train accuracy 87.89% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.09112 || train accuracy 89.14% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.09653 || train accuracy 87.11% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.07541 || train accuracy 91.02% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 85.06%, loss:  0.1 || best acc: 85.06%, best loss: 0.1\n",
      "Epoch[2/10] (20/82) || training loss 0.05432 || train accuracy 92.97% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.05149 || train accuracy 92.66% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.04621 || train accuracy 94.45% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.04457 || train accuracy 94.45% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 85.14%, loss: 0.12 || best acc: 85.14%, best loss: 0.1\n",
      "Epoch[3/10] (20/82) || training loss 0.03239 || train accuracy 96.72% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.0251 || train accuracy 97.50% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.02609 || train accuracy 97.73% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.03125 || train accuracy 96.17% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 84.91%, loss: 0.11 || best acc: 85.14%, best loss: 0.1\n",
      "Epoch[4/10] (20/82) || training loss 0.01856 || train accuracy 98.20% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.01429 || train accuracy 98.75% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.01664 || train accuracy 98.12% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.0131 || train accuracy 98.91% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 85.52%, loss: 0.13 || best acc: 85.52%, best loss: 0.1\n",
      "Epoch[5/10] (20/82) || training loss 0.008706 || train accuracy 99.30% || lr [5e-05]\n",
      "Epoch[5/10] (40/82) || training loss 0.01023 || train accuracy 98.67% || lr [5e-05]\n",
      "Epoch[5/10] (60/82) || training loss 0.008818 || train accuracy 99.14% || lr [5e-05]\n",
      "Epoch[5/10] (80/82) || training loss 0.008147 || train accuracy 99.14% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 85.75%, loss: 0.14 || best acc: 85.75%, best loss: 0.1\n",
      "Epoch[6/10] (20/82) || training loss 0.008232 || train accuracy 99.38% || lr [5e-05]\n",
      "Epoch[6/10] (40/82) || training loss 0.006749 || train accuracy 99.38% || lr [5e-05]\n",
      "Epoch[6/10] (60/82) || training loss 0.009385 || train accuracy 98.91% || lr [5e-05]\n",
      "Epoch[6/10] (80/82) || training loss 0.005488 || train accuracy 99.30% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 85.29%, loss: 0.16 || best acc: 85.75%, best loss: 0.1\n",
      "Epoch[7/10] (20/82) || training loss 0.005221 || train accuracy 99.53% || lr [5e-05]\n",
      "Epoch[7/10] (40/82) || training loss 0.005187 || train accuracy 99.53% || lr [5e-05]\n",
      "Epoch[7/10] (60/82) || training loss 0.005696 || train accuracy 99.22% || lr [5e-05]\n",
      "Epoch[7/10] (80/82) || training loss 0.006101 || train accuracy 99.30% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 84.83%, loss: 0.16 || best acc: 85.75%, best loss: 0.1\n",
      "Epoch[8/10] (20/82) || training loss 0.003969 || train accuracy 99.69% || lr [5e-05]\n",
      "Epoch[8/10] (40/82) || training loss 0.005108 || train accuracy 99.53% || lr [5e-05]\n",
      "Epoch[8/10] (60/82) || training loss 0.003663 || train accuracy 99.69% || lr [5e-05]\n",
      "Epoch[8/10] (80/82) || training loss 0.005754 || train accuracy 99.14% || lr [5e-05]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 85.06%, loss: 0.16 || best acc: 85.75%, best loss: 0.1\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.4343 || train accuracy 49.84% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.2836 || train accuracy 74.84% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.1796 || train accuracy 81.17% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.1569 || train accuracy 82.58% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 75.00%, loss: 0.21 || best acc: 75.00%, best loss:0.21\n",
      "Epoch[1/10] (20/82) || training loss 0.1133 || train accuracy 85.62% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.09003 || train accuracy 88.83% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.08306 || train accuracy 90.31% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.07496 || train accuracy 90.78% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 79.80%, loss: 0.15 || best acc: 79.80%, best loss:0.15\n",
      "Epoch[2/10] (20/82) || training loss 0.05477 || train accuracy 93.67% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.05118 || train accuracy 93.59% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.04358 || train accuracy 94.69% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.04423 || train accuracy 93.98% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 81.02%, loss: 0.15 || best acc: 81.02%, best loss:0.15\n",
      "Epoch[3/10] (20/82) || training loss 0.03143 || train accuracy 96.25% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.02654 || train accuracy 97.11% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.02447 || train accuracy 97.42% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.02037 || train accuracy 97.58% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 82.39%, loss: 0.19 || best acc: 82.39%, best loss:0.15\n",
      "Epoch[4/10] (20/82) || training loss 0.01728 || train accuracy 98.20% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.01677 || train accuracy 98.28% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.01435 || train accuracy 98.20% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.01115 || train accuracy 98.52% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 81.55%, loss: 0.25 || best acc: 82.39%, best loss:0.15\n",
      "Epoch[5/10] (20/82) || training loss 0.009663 || train accuracy 99.14% || lr [5e-05]\n",
      "Epoch[5/10] (40/82) || training loss 0.01124 || train accuracy 98.59% || lr [5e-05]\n",
      "Epoch[5/10] (60/82) || training loss 0.01091 || train accuracy 98.91% || lr [5e-05]\n",
      "Epoch[5/10] (80/82) || training loss 0.006676 || train accuracy 99.45% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 82.70%, loss: 0.22 || best acc: 82.70%, best loss:0.15\n",
      "Epoch[6/10] (20/82) || training loss 0.006175 || train accuracy 99.45% || lr [5e-05]\n",
      "Epoch[6/10] (40/82) || training loss 0.007292 || train accuracy 99.45% || lr [5e-05]\n",
      "Epoch[6/10] (60/82) || training loss 0.00504 || train accuracy 99.61% || lr [5e-05]\n",
      "Epoch[6/10] (80/82) || training loss 0.005248 || train accuracy 99.69% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 83.38%, loss: 0.23 || best acc: 83.38%, best loss:0.15\n",
      "Epoch[7/10] (20/82) || training loss 0.006503 || train accuracy 99.30% || lr [5e-05]\n",
      "Epoch[7/10] (40/82) || training loss 0.0055 || train accuracy 99.61% || lr [5e-05]\n",
      "Epoch[7/10] (60/82) || training loss 0.005504 || train accuracy 99.30% || lr [5e-05]\n",
      "Epoch[7/10] (80/82) || training loss 0.004132 || train accuracy 99.69% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 82.93%, loss: 0.23 || best acc: 83.38%, best loss:0.15\n",
      "Epoch[8/10] (20/82) || training loss 0.004433 || train accuracy 99.45% || lr [5e-05]\n",
      "Epoch[8/10] (40/82) || training loss 0.005196 || train accuracy 99.45% || lr [5e-05]\n",
      "Epoch[8/10] (60/82) || training loss 0.006355 || train accuracy 99.14% || lr [5e-05]\n",
      "Epoch[8/10] (80/82) || training loss 0.005021 || train accuracy 99.53% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 82.39%, loss: 0.26 || best acc: 83.38%, best loss:0.15\n",
      "Epoch[9/10] (20/82) || training loss 0.006347 || train accuracy 99.38% || lr [5e-05]\n",
      "Epoch[9/10] (40/82) || training loss 0.005488 || train accuracy 99.38% || lr [5e-05]\n",
      "Epoch[9/10] (60/82) || training loss 0.003937 || train accuracy 99.61% || lr [5e-05]\n",
      "Epoch[9/10] (80/82) || training loss 0.00454 || train accuracy 99.61% || lr [5e-05]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 83.00%, loss: 0.25 || best acc: 83.38%, best loss:0.15\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.4191 || train accuracy 55.62% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.2837 || train accuracy 75.00% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.1911 || train accuracy 80.55% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.1404 || train accuracy 84.06% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 78.58%, loss: 0.15 || best acc: 78.58%, best loss:0.15\n",
      "Epoch[1/10] (20/82) || training loss 0.09748 || train accuracy 87.03% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.09359 || train accuracy 88.12% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.08305 || train accuracy 90.23% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.07753 || train accuracy 90.16% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 83.84%, loss: 0.12 || best acc: 83.84%, best loss:0.12\n",
      "Epoch[2/10] (20/82) || training loss 0.05592 || train accuracy 93.75% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.05698 || train accuracy 92.81% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.04565 || train accuracy 94.69% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.03866 || train accuracy 95.00% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 84.38%, loss: 0.12 || best acc: 84.38%, best loss:0.12\n",
      "Epoch[3/10] (20/82) || training loss 0.03654 || train accuracy 95.70% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.0295 || train accuracy 96.80% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.02725 || train accuracy 97.19% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.03159 || train accuracy 96.33% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 84.22%, loss: 0.15 || best acc: 84.38%, best loss:0.12\n",
      "Epoch[4/10] (20/82) || training loss 0.01459 || train accuracy 98.44% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.01905 || train accuracy 97.50% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.02056 || train accuracy 97.11% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.01896 || train accuracy 97.81% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 85.37%, loss: 0.14 || best acc: 85.37%, best loss:0.12\n",
      "Epoch[5/10] (20/82) || training loss 0.009474 || train accuracy 99.30% || lr [5e-05]\n",
      "Epoch[5/10] (40/82) || training loss 0.0113 || train accuracy 98.67% || lr [5e-05]\n",
      "Epoch[5/10] (60/82) || training loss 0.01275 || train accuracy 98.44% || lr [5e-05]\n",
      "Epoch[5/10] (80/82) || training loss 0.01016 || train accuracy 99.14% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 85.29%, loss: 0.16 || best acc: 85.37%, best loss:0.12\n",
      "Epoch[6/10] (20/82) || training loss 0.006758 || train accuracy 99.45% || lr [5e-05]\n",
      "Epoch[6/10] (40/82) || training loss 0.007083 || train accuracy 99.30% || lr [5e-05]\n",
      "Epoch[6/10] (60/82) || training loss 0.008792 || train accuracy 99.53% || lr [5e-05]\n",
      "Epoch[6/10] (80/82) || training loss 0.008774 || train accuracy 99.06% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 85.29%, loss: 0.15 || best acc: 85.37%, best loss:0.12\n",
      "Epoch[7/10] (20/82) || training loss 0.007743 || train accuracy 99.14% || lr [5e-05]\n",
      "Epoch[7/10] (40/82) || training loss 0.005215 || train accuracy 99.53% || lr [5e-05]\n",
      "Epoch[7/10] (60/82) || training loss 0.006131 || train accuracy 99.38% || lr [5e-05]\n",
      "Epoch[7/10] (80/82) || training loss 0.005881 || train accuracy 99.45% || lr [5e-05]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 84.83%, loss: 0.16 || best acc: 85.37%, best loss:0.12\n",
      "Loaded pretrained weights for efficientnet-b4\n",
      "Epoch[0/10] (20/82) || training loss 0.4216 || train accuracy 52.50% || lr [0.0001]\n",
      "Epoch[0/10] (40/82) || training loss 0.2707 || train accuracy 75.00% || lr [0.0001]\n",
      "Epoch[0/10] (60/82) || training loss 0.1759 || train accuracy 81.48% || lr [0.0001]\n",
      "Epoch[0/10] (80/82) || training loss 0.1422 || train accuracy 84.14% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 78.96%, loss: 0.15 || best acc: 78.96%, best loss:0.15\n",
      "Epoch[1/10] (20/82) || training loss 0.108 || train accuracy 87.34% || lr [0.0001]\n",
      "Epoch[1/10] (40/82) || training loss 0.09823 || train accuracy 87.97% || lr [0.0001]\n",
      "Epoch[1/10] (60/82) || training loss 0.07882 || train accuracy 90.78% || lr [0.0001]\n",
      "Epoch[1/10] (80/82) || training loss 0.08552 || train accuracy 89.38% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 84.53%, loss:  0.1 || best acc: 84.53%, best loss: 0.1\n",
      "Epoch[2/10] (20/82) || training loss 0.05461 || train accuracy 94.22% || lr [0.0001]\n",
      "Epoch[2/10] (40/82) || training loss 0.05213 || train accuracy 93.44% || lr [0.0001]\n",
      "Epoch[2/10] (60/82) || training loss 0.05434 || train accuracy 93.36% || lr [0.0001]\n",
      "Epoch[2/10] (80/82) || training loss 0.0437 || train accuracy 94.84% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 88.03%, loss: 0.073 || best acc: 88.03%, best loss:0.073\n",
      "Epoch[3/10] (20/82) || training loss 0.03223 || train accuracy 96.95% || lr [0.0001]\n",
      "Epoch[3/10] (40/82) || training loss 0.02822 || train accuracy 96.64% || lr [0.0001]\n",
      "Epoch[3/10] (60/82) || training loss 0.02896 || train accuracy 96.72% || lr [0.0001]\n",
      "Epoch[3/10] (80/82) || training loss 0.02874 || train accuracy 96.25% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 86.28%, loss: 0.11 || best acc: 88.03%, best loss:0.073\n",
      "Epoch[4/10] (20/82) || training loss 0.01416 || train accuracy 98.67% || lr [0.0001]\n",
      "Epoch[4/10] (40/82) || training loss 0.01827 || train accuracy 98.12% || lr [0.0001]\n",
      "Epoch[4/10] (60/82) || training loss 0.01476 || train accuracy 98.05% || lr [0.0001]\n",
      "Epoch[4/10] (80/82) || training loss 0.0153 || train accuracy 98.59% || lr [0.0001]\n",
      "Calculating validation results\n",
      "[Val] acc: 88.19%, loss: 0.12 || best acc: 88.19%, best loss:0.073\n",
      "Epoch[5/10] (20/82) || training loss 0.01186 || train accuracy 98.36% || lr [5e-05]\n",
      "Epoch[5/10] (40/82) || training loss 0.008275 || train accuracy 99.30% || lr [5e-05]\n",
      "Epoch[5/10] (60/82) || training loss 0.008494 || train accuracy 99.22% || lr [5e-05]\n",
      "Epoch[5/10] (80/82) || training loss 0.009157 || train accuracy 99.14% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 88.41%, loss: 0.11 || best acc: 88.41%, best loss:0.073\n",
      "Epoch[6/10] (20/82) || training loss 0.008673 || train accuracy 99.14% || lr [5e-05]\n",
      "Epoch[6/10] (40/82) || training loss 0.008475 || train accuracy 99.14% || lr [5e-05]\n",
      "Epoch[6/10] (60/82) || training loss 0.006439 || train accuracy 99.38% || lr [5e-05]\n",
      "Epoch[6/10] (80/82) || training loss 0.007747 || train accuracy 99.06% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 87.58%, loss: 0.12 || best acc: 88.41%, best loss:0.073\n",
      "Epoch[7/10] (20/82) || training loss 0.007289 || train accuracy 99.53% || lr [5e-05]\n",
      "Epoch[7/10] (40/82) || training loss 0.00649 || train accuracy 99.30% || lr [5e-05]\n",
      "Epoch[7/10] (60/82) || training loss 0.007282 || train accuracy 99.22% || lr [5e-05]\n",
      "Epoch[7/10] (80/82) || training loss 0.005126 || train accuracy 99.69% || lr [5e-05]\n",
      "Calculating validation results\n",
      "[Val] acc: 87.42%, loss: 0.14 || best acc: 88.41%, best loss:0.073\n",
      "Epoch[8/10] (20/82) || training loss 0.005099 || train accuracy 99.61% || lr [5e-05]\n",
      "Epoch[8/10] (40/82) || training loss 0.007033 || train accuracy 99.22% || lr [5e-05]\n",
      "Epoch[8/10] (60/82) || training loss 0.005296 || train accuracy 99.45% || lr [5e-05]\n",
      "Epoch[8/10] (80/82) || training loss 0.005375 || train accuracy 99.61% || lr [5e-05]\n",
      "Calculating validation results\n",
      "Early Stopping\n",
      "[Val] acc: 87.80%, loss: 0.12 || best acc: 88.41%, best loss:0.073\n"
     ]
    }
   ],
   "source": [
    "# for 문을 3번 (mask, gender, age)을 반복 합니다.\n",
    "for k in range(3):\n",
    "    \n",
    "    # 각 k-fold 별로 생성되는 모델을 저장할 폴더 생성\n",
    "    if not os.path.exists(RESULT_PATH[k]):\n",
    "        os.mkdir(RESULT_PATH[k])\n",
    "    \n",
    "    # 각 모델별로 dataset 생성\n",
    "    # ex) class_by = TARGET[0] -> class_by='mask'\n",
    "    dataset = MaskSplitByProfileDataset(data_dir = '../../input/data/train/images', class_by=TARGET[k])\n",
    "    transform = CustomAugmentation(resize=(256, 256), mean=dataset.mean, std=dataset.std)\n",
    "    dataset.set_transform(transform)\n",
    "    \n",
    "    # k-fold 적용을 위한 k 값 설정\n",
    "    n_splits = 5\n",
    "    skf = StratifiedKFold(n_splits=n_splits)\n",
    "    \n",
    "    \n",
    "    # patience = 2 -> 2번동안 더 좋은 모델이 안나오면 early stop\n",
    "    patience = 2\n",
    "    \n",
    "    # epoch를 2번 돌았을 때 grad 업데이트 합니다.\n",
    "    accumulation_steps = 2\n",
    "    oof_pred = None\n",
    "\n",
    "    labels = [dataset.encode_multi_class(mask, gender, age) for mask, gender, age in zip(dataset.mask_labels, dataset.gender_labels, dataset.age_labels)]\n",
    "    \n",
    "    # train, validation을 4:1 로 비율을 나누어 차례대로 학습을 합니다. (총 5회)\n",
    "    for i, (train_idx, valid_idx) in enumerate(skf.split(dataset.image_paths, labels)):\n",
    "        train_loader, val_loader = get_dataloader(dataset, train_idx, valid_idx, batch_size, num_workers)\n",
    "\n",
    "        # -- model\n",
    "        # CLASS[k] -> output size ex) mask는 3개의 output size를 가집니다 (착용, 미착용, 비정상착용)\n",
    "        #target_model = model.get_model('efficientnet_b4', CLASS[k]).to(device)\n",
    "        target_model = efficientnetb4(classes=CLASS[k]).to(device)\n",
    "\n",
    "        # -- loss & matric\n",
    "        loss_fn = FocalLoss()\n",
    "        optimizer = AdamW(target_model.parameters(), lr = learning_rate, weight_decay=5e-4)\n",
    "        scheduler = StepLR(optimizer, lr_decay_step, gamma=0.5)\n",
    "\n",
    "        best_model_path = None\n",
    "        counter = 0\n",
    "        best_val_acc = 0\n",
    "        best_val_loss = np.inf\n",
    "        \n",
    "        # epoch loop\n",
    "        for epoch in range(epochs):\n",
    "            target_model.train()\n",
    "            loss_value = 0\n",
    "            matches = 0\n",
    "            \n",
    "            # train loop\n",
    "            for idx, train_batch in enumerate(train_loader):\n",
    "                inputs, labels = train_batch\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                outputs = target_model(inputs)\n",
    "                preds = torch.argmax(outputs, dim=-1)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                if(idx+1) % accumulation_steps == 0:\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                loss_value += loss.item()\n",
    "                matches += (preds == labels).sum().item()\n",
    "\n",
    "                if(idx + 1) % train_log_interval == 0:\n",
    "                    train_loss = loss_value / train_log_interval\n",
    "                    train_acc = matches / batch_size / train_log_interval\n",
    "                    current_lr = scheduler.get_last_lr()\n",
    "                    print(\n",
    "                        f\"Epoch[{epoch}/{epochs}] ({idx + 1}/{len(train_loader)}) || \"\n",
    "                        f\"training loss {train_loss:4.4} || train accuracy {train_acc:4.2%} || lr {current_lr}\"\n",
    "                    )\n",
    "                    loss_value = 0\n",
    "                    matches = 0\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "            # val loop\n",
    "            with torch.no_grad():\n",
    "                print(\"Calculating validation results\")\n",
    "                target_model.eval()\n",
    "                val_loss_items = []\n",
    "                val_acc_items = []\n",
    "\n",
    "                for val_batch in val_loader:\n",
    "                    inputs, labels = val_batch\n",
    "                    inputs = inputs.to(device)\n",
    "                    labels = labels.to(device)\n",
    "\n",
    "                    outputs = target_model(inputs)\n",
    "                    preds = torch.argmax(outputs, dim=-1)\n",
    "\n",
    "                    loss_item = loss_fn(outputs, labels).item()\n",
    "                    acc_item = (labels == preds).sum().item()\n",
    "                    val_loss_items.append(loss_item)\n",
    "                    val_acc_items.append(acc_item)\n",
    "\n",
    "                val_loss = np.sum(val_loss_items) / len(val_loader)\n",
    "                val_acc = np.sum(val_acc_items) / len(valid_idx)\n",
    "\n",
    "                # Callback: validation accuracy가 향상될수록 모델을 저장\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                if val_acc > best_val_acc: # 향상 되면 RESULT_PATH[k] 폴더에 저장\n",
    "                    torch.save(target_model, os.path.join(RESULT_PATH[k], f\"{i:02}_{epoch:03}_acc_{val_acc:4.2}.ckpt\"))\n",
    "                    best_val_acc = val_acc\n",
    "                    counter = 0\n",
    "                    best_model_path = os.path.join(RESULT_PATH[k], f\"{i:02}_{epoch:03}_acc_{val_acc:4.2}.ckpt\")\n",
    "\n",
    "                else:\n",
    "                    counter += 1\n",
    "\n",
    "                if counter > patience:\n",
    "                    print(\"Early Stopping\")\n",
    "                    print(\n",
    "                        f\"[Val] acc: {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n",
    "                        f\"best acc: {best_val_acc:4.2%}, best loss:{best_val_loss:4.2}\"\n",
    "                    )\n",
    "                    break\n",
    "\n",
    "                print(\n",
    "                    f\"[Val] acc: {val_acc:4.2%}, loss: {val_loss:4.2} || \"\n",
    "                    f\"best acc: {best_val_acc:4.2%}, best loss:{best_val_loss:4.2}\"\n",
    "                )\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49b90c5f-1dda-4bcf-b52c-020221970c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test 데이터 경로 지정 및 로드\n",
    "test_img_root = '../../input/data/eval/'\n",
    "img_dir = os.path.join(test_img_root, 'images')\n",
    "submission = pd.read_csv(os.path.join(test_img_root, 'info.csv'))\n",
    "\n",
    "image_paths = [os.path.join(img_dir, img_id) for img_id in submission.ImageID]\n",
    "testset = TestDataset(image_paths, resize=(256, 256))\n",
    "test_loader = torch.utils.data.DataLoader(testset, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "306fa45e-3858-4cd4-a062-39d2c93c17d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(model):\n",
    "    k, epoch, _, acc = model.split('_')\n",
    "    acc1, acc2, _ = acc.split('.')\n",
    "    acc = '.'.join([acc1, acc2])\n",
    "    return k, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7a707f7-ed1f-4e19-8342-fc30d41ec06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best(path):\n",
    "    model_list = [model for model in os.listdir(path) if not model.startswith('.')]\n",
    "    best_model={}\n",
    "    for model in model_list:\n",
    "        k, acc = get_info(model)\n",
    "        try:\n",
    "            _k, _acc = get_info(best_model[int(k)])\n",
    "            if float(acc) > float(_acc):\n",
    "                best_model[int(k)] = model\n",
    "        except:\n",
    "            best_model[int(k)] = model\n",
    "    \n",
    "    return list(best_model.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdabd635-d2d8-4138-8825-a018c42bace3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working path: k-fold-mask-b4\n",
      "loaded best model for this fold, 02_001_acc_0.99.ckpt\n",
      "loaded best model for this fold, 03_004_acc_0.99.ckpt\n",
      "loaded best model for this fold, 01_003_acc_0.99.ckpt\n",
      "loaded best model for this fold, 00_002_acc_0.99.ckpt\n",
      "loaded best model for this fold, 04_002_acc_0.99.ckpt\n",
      "current working path: k-fold-gender-b4\n",
      "loaded best model for this fold, 00_001_acc_0.98.ckpt\n",
      "loaded best model for this fold, 02_007_acc_0.98.ckpt\n",
      "loaded best model for this fold, 03_006_acc_0.97.ckpt\n",
      "loaded best model for this fold, 04_002_acc_0.98.ckpt\n",
      "loaded best model for this fold, 01_005_acc_0.97.ckpt\n",
      "current working path: k-fold-age-b4\n",
      "loaded best model for this fold, 01_008_acc_0.86.ckpt\n",
      "loaded best model for this fold, 04_005_acc_0.88.ckpt\n",
      "loaded best model for this fold, 02_003_acc_0.87.ckpt\n",
      "loaded best model for this fold, 00_002_acc_0.86.ckpt\n",
      "loaded best model for this fold, 03_009_acc_0.87.ckpt\n"
     ]
    }
   ],
   "source": [
    "combine = {}\n",
    "n_splits = 5\n",
    "# 각 도메인(mask, gender, age) 별로 루프 동작\n",
    "for i, PATH in enumerate(RESULT_PATH):\n",
    "    print('current working path:', PATH)\n",
    "    best_models = get_best(PATH)\n",
    "    oof_pred = None\n",
    "    for best_model_path in best_models:\n",
    "        best_model = torch.load(os.path.join(PATH, best_model_path))\n",
    "        print(f\"loaded best model for this fold, {best_model_path}\")\n",
    "        all_predictions = []\n",
    "        with torch.no_grad():\n",
    "            for images in test_loader:\n",
    "                images = images.to(device)\n",
    "\n",
    "                pred = best_model(images) #/ 2\n",
    "                #pred += best_model(torch.flip(images, [0, 1])) / 2\n",
    "                all_predictions.extend(pred.cpu().numpy())\n",
    "\n",
    "            fold_pred = np.array(all_predictions)\n",
    "\n",
    "        if oof_pred is None:\n",
    "            oof_pred = fold_pred / n_splits\n",
    "        else:\n",
    "            oof_pred += fold_pred / n_splits\n",
    "            \n",
    "    combine[TARGET[i]] = np.argmax(oof_pred, axis=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c466b401-1bd8-4ede-8a2f-6680b2ac0039",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bf10473-dff4-436e-8ed9-3d3152372852",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save data\n",
    "with open('combine.pickle','wb') as fw:\n",
    "    pickle.dump(combine, fw)\n",
    "\n",
    "# load data\n",
    "# with open('combine.pickle', 'rb') as fr:\n",
    "#     combine = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46e20460-4935-49bc-b23a-e50b3b655715",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_multi_class(mask_label, gender_label, age_label) -> int:\n",
    "        return mask_label * 6 + gender_label * 3 + age_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b26ec5b-7e1a-46dd-9dd6-0304d891de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_class =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2c8d26c-e655-41f1-9ef1-10e6ed067c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mask, gender, age in zip(combine['mask'], combine['gender'], combine['age']):\n",
    "    multi_class.append(encode_multi_class(mask, gender, age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2917b842-494b-4b1b-842b-39b0dfd42ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv(os.path.join(test_img_root, 'info.csv'))\n",
    "submission['ans'] = multi_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "898160b8-df5c-47e5-9c83-471bb85b6d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('efficientb4twoAdamW.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6debb65-1ab0-4fb7-a003-8db1572c69e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
